{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing and Feature Engineering"
      ],
      "metadata": {
        "id": "SINWZA0iXuqU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eHSZDE7XriD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from textstat import textstat\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import shap\n",
        "import re\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and clean data"
      ],
      "metadata": {
        "id": "O9IYTOQxX0hQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('processed_essays.csv')\n",
        "df['cleaned_essay'] = df['essay'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x.lower()))"
      ],
      "metadata": {
        "id": "p5qgKQY6X2jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature extraction\n"
      ],
      "metadata": {
        "id": "oNOxWzt1X3oU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['word_count'] = df['cleaned_essay'].apply(lambda x: len(x.split()))\n",
        "df['flesch_reading_ease'] = df['cleaned_essay'].apply(textstat.flesch_reading_ease)\n",
        "df['vocab_richness'] = df['cleaned_essay'].apply(lambda x: len(set(word_tokenize(x))) / len(word_tokenize(x)))\n",
        "df['avg_sentence_length'] = df['cleaned_essay'].apply(lambda x: np.mean([len(sentence.split()) for sentence in nltk.sent_tokenize(x)]))"
      ],
      "metadata": {
        "id": "CAFbuuBOX5vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF feature extraction\n"
      ],
      "metadata": {
        "id": "zeavfLP8X7V-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(max_features=100)\n",
        "tfidf_matrix = tfidf.fit_transform(df['cleaned_essay'])\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n",
        "df = pd.concat([df, tfidf_df], axis=1)"
      ],
      "metadata": {
        "id": "NcrVlVeqX8cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model training with RandomizedSearchCV\n"
      ],
      "metadata": {
        "id": "VINkLicaX9r_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['essay', 'cleaned_essay', 'grade'], axis=1)\n",
        "y = df['grade']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 500, 1000],\n",
        "    'max_depth': [10, 20, 30, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "random_search = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=50, cv=5, random_state=42, n_jobs=-1)\n",
        "random_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "8XytKlflX_yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model evaluation\n"
      ],
      "metadata": {
        "id": "2E4Tvb9NYD1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_rf = random_search.best_estimator_\n",
        "y_pred = best_rf.predict(X_test)\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "N8tO27e-YFSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interpret model with SHAP\n"
      ],
      "metadata": {
        "id": "rtQT0dXtYGYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = shap.TreeExplainer(best_rf)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "shap.summary_plot(shap_values, X_test, plot_type=\"bar\", feature_names=X.columns)"
      ],
      "metadata": {
        "id": "8s4oUkXhYJCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion Matrix"
      ],
      "metadata": {
        "id": "T2t_3vf5YkJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=best_rf.classes_, yticklabels=best_rf.classes_)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Grades')\n",
        "plt.ylabel('Actual Grades')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "z3Wz_wyFYlfJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}